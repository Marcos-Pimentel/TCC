{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a JSON file\n",
    "def read_input(file):\n",
    "    content = None\n",
    "    with open(file, \"r\") as arq:\n",
    "        content = json.load(arq)\n",
    "    return content\n",
    "\n",
    "def import_floyd_warshall(filename):\n",
    "    graph = nx.Graph()\n",
    "    with open(filename) as file:\n",
    "        data = json.load(file)\n",
    "    graph.add_edges_from([(int(re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[0]), int(re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[1]), data[\"EDGES\"][x]) for x in data[\"EDGES\"].keys() if (re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[0] <= re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[1])])\n",
    "    return nx.floyd_warshall_predecessor_and_distance(graph, weight=\"DISTANCE\")[1]\n",
    "\n",
    "\n",
    "def func_edges_sigma(edges_S, edges_sigma):\n",
    "    to_return = list()\n",
    "    for s in edges_S:\n",
    "        to_return.append(edges_sigma[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "\n",
    "#read the JSON file\n",
    "input_content = read_input('Test/Lpr-a-01.json')\n",
    "\n",
    "#TOLERANCE (values suggested by Garcia-Ayala's paper)\n",
    "tolerance = (0.1, 0.05)\n",
    "\n",
    "#DEPOTS\n",
    "#list of depots\n",
    "#format: [1, 2, 3]\n",
    "depots = list()\n",
    "for p in input_content['DEPOTS']:\n",
    "    depots.append(int(p))\n",
    "\n",
    "#VERTICES\n",
    "#list of vertices\n",
    "#format: [1, 2, 3, 4]\n",
    "vertices = list()\n",
    "# for i in input_content['NODES'].keys():\n",
    "#     vertices.append(int(i))\n",
    "\n",
    "dictionary = dict()\n",
    "\n",
    "# for a in input_content['NODES'].keys():\n",
    "#     for b in input_content['NODES'][a].keys():\n",
    "#         if (int(b),int(a)) not in dictionary.keys():\n",
    "#             dictionary[int(a),int(b)] = int(input_content['NODES'][a][b]['DISTANCE']),int(input_content['NODES'][a][b]['DEMAND'])\n",
    "\n",
    "for e in input_content['EDGES'].keys():\n",
    "    e_aux = e.split(',')\n",
    "    a = int(e_aux[0].split('(')[1])\n",
    "    b = int(e_aux[1].split(')')[0])\n",
    "    if (b,a) not in dictionary.keys():\n",
    "        dictionary[a,b] = int(input_content['EDGES'][e]['DISTANCE']),int(input_content['EDGES'][e]['DEMAND'])\n",
    "    if a not in vertices:\n",
    "        vertices.append(a)\n",
    "\n",
    "#EDGES\n",
    "#format: (2, 14)\n",
    "#        (2, 3)\n",
    "#DISTANCE\n",
    "#format: {(2, 14): 34, (2, 3): 19}\n",
    "#DEMAND\n",
    "#format: {(2, 14): 240, (2, 3): 137}\n",
    "edges, distance, demand = gp.multidict(dictionary)\n",
    "\n",
    "#AVERAGE DEMAND\n",
    "avg_demand = 0\n",
    "for d in demand.keys():\n",
    "    avg_demand += demand[d]\n",
    "\n",
    "avg_demand /= len(depots)\n",
    "\n",
    "#EDGES DELTA\n",
    "#dictionary of all the edges that have 'i' as one of its ends\n",
    "#format: {2: [(2, 14), (2, 3), (2, 8)], 14: [(2, 14), (14, 7)]}\n",
    "edges_delta = dict()\n",
    "\n",
    "for i in vertices:\n",
    "    edges_delta[i] = list()\n",
    "    for e in edges:\n",
    "        if e[0] == i or e[1] == i:\n",
    "            edges_delta[i].append(e)\n",
    "\n",
    "#DEPOT VERTEX\n",
    "#tuples that relate a depot to a vertex\n",
    "#format: [(1, 2), (1, 14)]\n",
    "depot_vertex = list()\n",
    "\n",
    "for p in depots:\n",
    "    for i in vertices:\n",
    "        depot_vertex.append((p, i))\n",
    "\n",
    "matrix2 = import_floyd_warshall('Test/Lpr-a-01.json')\n",
    "\n",
    "dictionary = dict()\n",
    "for p in depots:\n",
    "    for e in edges:\n",
    "        dictionary[p,e] = min(matrix2[p][e[0]],matrix2[p][e[1]])\n",
    "\n",
    "\n",
    "#DEPOT EDGE\n",
    "#tuples that relate a depot to an edge\n",
    "#format: ( 1 , (2, 14)  )\n",
    "#        ( 1 , (2, 3)   )\n",
    "#DEPOT DISTANCE\n",
    "#dictionary with the distance between a depot and an edge\n",
    "#format: {(1, (2, 14)): 60, (1, (2, 3)): 41}\n",
    "depot_edge, depot_dist = gp.multidict(dictionary)\n",
    "\n",
    "dictionary = dict()\n",
    "\n",
    "#PARITY LOOSE\n",
    "# list of vertices to assign if a vertex loose its parity or not\n",
    "parity_loose = list()\n",
    "\n",
    "#list of even parity vertices\n",
    "vertices_even = list()\n",
    "#list of odd parity vertices\n",
    "vertices_odd = list()\n",
    "\n",
    "for i in range(len(vertices)+1):\n",
    "    dictionary[i] = 0\n",
    "    if i != 0:\n",
    "        parity_loose.append(i)\n",
    "\n",
    "for e in edges:\n",
    "    dictionary[e[0]] += 1\n",
    "    dictionary[e[1]] += 1\n",
    "\n",
    "for i in range(len(vertices)+1):\n",
    "    if i != 0 and dictionary[i]%2 == 0:\n",
    "        vertices_even.append(i)\n",
    "    elif i != 0 and dictionary[i]%2 == 1:\n",
    "        vertices_odd.append(i)\n",
    "\n",
    "dictionary = dict()\n",
    "\n",
    "for i in vertices:\n",
    "    for p in depots:\n",
    "        dictionary[i,p] = 0\n",
    "\n",
    "#PARITY\n",
    "#dictionary that relates a vertex and a depot, and indicates its parity\n",
    "parity = dictionary\n",
    "#the same as the above but binary\n",
    "parity_0 = dictionary\n",
    "\n",
    "edges_sigma = dict()\n",
    "edges_S = dict()\n",
    "for e in edges:\n",
    "    edges_sigma[e] = list()\n",
    "    edges_S[e] = list()\n",
    "    for f in edges:\n",
    "        if (e[0] == f[0] or e[0] == f[1] or e[1] == f[0] or e[1] == f[1]) and (e != f):\n",
    "            edges_sigma[e].append(f)\n",
    "        elif (e != f):\n",
    "            edges_S[e].append(f)\n",
    "\n",
    "edges_sigma_S = dict()\n",
    "for e in edges:\n",
    "    edges_sigma_S[e] = list()\n",
    "    for i in edges_S[e]:\n",
    "        for j in edges_sigma[i]:\n",
    "            edges_sigma_S[e].append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-29\n"
     ]
    }
   ],
   "source": [
    "#declare model\n",
    "model = gp.Model('RAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision variables\n",
    "b = model.addVars(depot_dist, name=\"DepotEdgeDistance\")\n",
    "x = model.addVars(depot_edge, vtype=gp.GRB.BINARY, name=\"DepotEdgeAssign\")\n",
    "w = model.addVars(depot_vertex, vtype=gp.GRB.BINARY, name=\"DepotVertexIncident\")\n",
    "z = model.addVars(parity, lb = 0, name = \"Parity\")\n",
    "z_0 = model.addVars(parity_0, vtype=gp.GRB.BINARY, name = \"OddParity\")\n",
    "r = model.addVars(parity_loose, vtype=gp.GRB.BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constrains\n",
    "constrain_2 = model.addConstrs((gp.quicksum(x[p,e] for p in depots) == 1 for e in edges), name='constrain2')\n",
    "#constrain_3 = model.addConstrs((gp.quicksum(x[p,s] for s in edges_sigma_S[e]) - gp.quicksum(x[p,s] for s in edges_S[e]) >= x[p,e] - len(edges_S[e]) for p in depots for e in edges for S in edges), name='constrain 3')\n",
    "constrain_4 = model.addConstrs((gp.quicksum(x[p,e]*demand[e] for e in edges) <= avg_demand*(1 + tolerance[0]) for p in depots), name='constrain4')\n",
    "constrain_5 = model.addConstrs((gp.quicksum(x[p,e]*demand[e] for e in edges) >= avg_demand*(1 - tolerance[0]) for p in depots), name='constrain5')\n",
    "constrain_6 = model.addConstrs((gp.quicksum(x[p,e] for e in edges_delta[i]) <= 9999*w[p,i] for p in depots for i in vertices), name='constrain6')\n",
    "constrain_7 = model.addConstrs((gp.quicksum(x[p,e] for e in edges_delta[i]) >= w[p,i] for p in depots for i in vertices), name='constrain7')\n",
    "constrain_8 = model.addConstrs((gp.quicksum(x[p,e] for e in edges_delta[i]) == 2*z[i,p]+z_0[i,p] for p in depots for i in vertices), name='constrain8')\n",
    "constrain_9 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) >= r[i] for i in vertices_even), name='constrain9')\n",
    "constrain_10 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) <= r[i]*len(depots) for i in vertices_even), name='constrain10')\n",
    "constrain_11 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) - 1 >= r[i] for i in vertices_odd), name='constrain11')\n",
    "constrain_12 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) - 1 <= r[i]*len(depots) for i in vertices_odd), name='constrain12')\n",
    "constrain_13 = model.addConstr((gp.quicksum(r[i] for i in vertices)/len(vertices) <= tolerance[1]), name='constrain13')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objective\n",
    "model.setObjective(x.prod(depot_dist), GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "model.write('RAP.rlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback\n",
    "def edges_to_graph(regex_edges):\n",
    "    graph = defaultdict(list)\n",
    "    for e in regex_edges.keys():\n",
    "        if regex_edges[e] > 0.9:\n",
    "            graph[e[0]].append(e[1])\n",
    "            graph[e[1]].append(e[0])\n",
    "    return graph\n",
    "\n",
    "def breadth_first_search(graph, depot):\n",
    "    visited = dict()\n",
    "    for i in graph.keys():\n",
    "        visited[i] = False\n",
    "\n",
    "    queue = []\n",
    "\n",
    "    queue.append(depot)\n",
    "    visited[depot] = True\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        for i in graph[node]:\n",
    "            if visited[i] == False:\n",
    "                queue.append(i)\n",
    "                visited[i] = True\n",
    "    \n",
    "    to_return = list()\n",
    "    for i in visited:\n",
    "        if i == False:\n",
    "            for e in graph[i]:\n",
    "                if (e,i) in edges and (e,i) not in to_return:\n",
    "                    to_return.append((e,i))\n",
    "                elif (i,e) in edges and (i,e) not in to_return:\n",
    "                    to_return.append((i,e))\n",
    "        \n",
    "    \n",
    "    return to_return\n",
    "\n",
    "def variable_regex(depot):\n",
    "    name = list()\n",
    "    for var in model.getVars():\n",
    "        if \"DepotEdgeAssign[\"+str(depot)+\",(\" in var.varName:\n",
    "            name.append(var)\n",
    "    \n",
    "    value = model.cbGetSolution(name)\n",
    "    to_return = dict()\n",
    "\n",
    "    for i in range(len(edges)):\n",
    "        to_return[edges[i]] = value[i]\n",
    "\n",
    "    return to_return\n",
    "    \n",
    "\n",
    "def mycallback(model, where):\n",
    "    if where == GRB.Callback.MIPSOL:\n",
    "        for p in depots:\n",
    "            unreached_edges = breadth_first_search(edges_to_graph(variable_regex(p)), p)\n",
    "            if len(unreached_edges) > 0:\n",
    "                cuts = model.addConstrs((gp.quicksum(x[p,s] for s in edges_sigma[e]) - x[p,e] >= 0 for e in unreached_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-3610QM CPU @ 2.30GHz, instruction set [SSE2|AVX]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 448 rows, 740 columns and 2352 nonzeros\n",
      "Model fingerprint: 0x143618ea\n",
      "Variable types: 300 continuous, 440 integer (440 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 1e+04]\n",
      "  Objective range  [1e+01, 1e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [5e-02, 2e+03]\n",
      "Presolved: 240 rows, 336 columns, 1368 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      "\n",
      "Explored 1 nodes (119 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1601 2256 2544 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.601000000000e+03, best bound 1.601000000000e+03, gap 0.0000%\n",
      "\n",
      "User-callback calls 27, time in user-callback 0.00 sec\n"
     ]
    }
   ],
   "source": [
    "#run\n",
    "model.optimize(mycallback)\n",
    "aaa = \"this\"\n",
    "model.write(\"Test/{}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
