{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a JSON file\n",
    "def read_input(file):\n",
    "    content = None\n",
    "    with open(file, \"r\") as arq:\n",
    "        content = json.load(arq)\n",
    "    return content\n",
    "\n",
    "def import_floyd_warshall(filename):\n",
    "    graph = nx.Graph()\n",
    "    with open(filename) as file:\n",
    "        data = json.load(file)\n",
    "    graph.add_edges_from([(int(re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[0]), int(re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[1]), data[\"EDGES\"][x]) for x in data[\"EDGES\"].keys() if (re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[0] <= re.findall(\"(?<!\\d)\\d+(?!\\d)\",x)[1])])\n",
    "    return nx.floyd_warshall_predecessor_and_distance(graph, weight=\"DISTANCE\")[1]\n",
    "\n",
    "\n",
    "def func_edges_sigma(edges_S, edges_sigma):\n",
    "    to_return = list()\n",
    "    for s in edges_S:\n",
    "        to_return.append(edges_sigma[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "depots = None\n",
    "edges = None\n",
    "model = None\n",
    "edges_sigma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback\n",
    "def edges_to_graph(regex_edges):\n",
    "    graph = defaultdict(list)\n",
    "    for e in regex_edges.keys():\n",
    "        if regex_edges[e] > 0.9:\n",
    "            graph[e[0]].append(e[1])\n",
    "            graph[e[1]].append(e[0])\n",
    "    return graph\n",
    "\n",
    "def breadth_first_search(graph, depot):\n",
    "    visited = dict()\n",
    "    for i in graph.keys():\n",
    "        visited[i] = False\n",
    "\n",
    "    queue = []\n",
    "\n",
    "    queue.append(depot)\n",
    "    visited[depot] = True\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        for i in graph[node]:\n",
    "            if visited[i] == False:\n",
    "                queue.append(i)\n",
    "                visited[i] = True\n",
    "    \n",
    "    to_return = list()\n",
    "    for i in visited:\n",
    "        if i == False:\n",
    "            for e in graph[i]:\n",
    "                if (e,i) in edges and (e,i) not in to_return:\n",
    "                    to_return.append((e,i))\n",
    "                elif (i,e) in edges and (i,e) not in to_return:\n",
    "                    to_return.append((i,e))\n",
    "        \n",
    "    \n",
    "    return to_return\n",
    "\n",
    "def variable_regex(depot):\n",
    "    name = list()\n",
    "    for var in model.getVars():\n",
    "        if \"DepotEdgeAssign[\"+str(depot)+\",(\" in var.varName:\n",
    "            name.append(var)\n",
    "    \n",
    "    value = model.cbGetSolution(name)\n",
    "    to_return = dict()\n",
    "\n",
    "    for i in range(len(edges)):\n",
    "        to_return[edges[i]] = value[i]\n",
    "\n",
    "    return to_return\n",
    "\n",
    "def variable_regex_final(depot):\n",
    "    name = list()\n",
    "    for var in model.getVars():\n",
    "        if \"DepotEdgeAssign[\"+str(depot)+\",(\" in var.varName:\n",
    "            name.append(var)\n",
    "    \n",
    "    value = model.getAttr(\"X\",name)\n",
    "    to_return = dict()\n",
    "\n",
    "    for i in range(len(edges)):\n",
    "        to_return[edges[i]] = value[i]\n",
    "\n",
    "    return to_return\n",
    "    \n",
    "\n",
    "def mycallback(model, where):\n",
    "    if where == GRB.Callback.MIPSOL:\n",
    "        for p in depots:\n",
    "            unreached_edges = breadth_first_search(edges_to_graph(variable_regex(p)), p)\n",
    "            if len(unreached_edges) > 0:\n",
    "                cuts = model.addConstrs((gp.quicksum(x[p,s] for s in edges_sigma[e]) - x[p,e] >= 0 for e in unreached_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lpr-a-01.json', 'Lpr-a-02.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "path = \"Test/\"\n",
    "\n",
    "print(next(walk(path), (None, None, []))[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputfile\n",
      "Lpr-a-01.json\n",
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-3610QM CPU @ 2.30GHz, instruction set [SSE2|AVX]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 448 rows, 740 columns and 2352 nonzeros\n",
      "Model fingerprint: 0x143618ea\n",
      "Variable types: 300 continuous, 440 integer (440 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 1e+04]\n",
      "  Objective range  [1e+01, 1e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [5e-02, 2e+03]\n",
      "Found heuristic solution: objective 2544.0000000\n",
      "Presolve removed 208 rows and 404 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 240 rows, 336 columns, 1368 nonzeros\n",
      "Variable types: 0 continuous, 336 integer (336 binary)\n",
      "Found heuristic solution: objective 2256.0000000\n",
      "\n",
      "Root relaxation: objective 1.582784e+03, 94 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1582.78389    0    7 2256.00000 1582.78389  29.8%     -    0s\n",
      "H    0     0                    1601.0000000 1582.78389  1.14%     -    0s\n",
      "     0     0 1596.49081    0    8 1601.00000 1596.49081  0.28%     -    0s\n",
      "     0     0     cutoff    0      1601.00000 1601.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (119 simplex iterations) in 0.09 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1601 2256 2544 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.601000000000e+03, best bound 1.601000000000e+03, gap 0.0000%\n",
      "\n",
      "User-callback calls 335, time in user-callback 0.05 sec\n",
      "inputfile\n",
      "Lpr-a-02.json\n",
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-3610QM CPU @ 2.30GHz, instruction set [SSE2|AVX]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 837 rows, 1377 columns and 4359 nonzeros\n",
      "Model fingerprint: 0x4647e7ad\n",
      "Variable types: 556 continuous, 821 integer (821 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 1e+04]\n",
      "  Objective range  [2e+01, 3e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [5e-02, 5e+03]\n",
      "Found heuristic solution: objective 10770.000000\n",
      "Presolve removed 382 rows and 749 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 455 rows, 628 columns, 2632 nonzeros\n",
      "Variable types: 0 continuous, 628 integer (628 binary)\n",
      "Found heuristic solution: objective 10235.000000\n",
      "\n",
      "Root relaxation: objective 9.569246e+03, 211 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 9569.24627    0   12 10235.0000 9569.24627  6.50%     -    0s\n",
      "H    0     0                    9592.0000000 9569.24627  0.24%     -    0s\n",
      "H    0     0                    9591.0000000 9569.37393  0.23%     -    0s\n",
      "     0     0 9570.09532    0   15 9591.00000 9570.09532  0.22%     -    0s\n",
      "     0     0 9570.09532    0   10 9591.00000 9570.09532  0.22%     -    0s\n",
      "     0     0 9574.85748    0   17 9591.00000 9574.85748  0.17%     -    0s\n",
      "     0     0 9585.32670    0   18 9591.00000 9585.32670  0.06%     -    0s\n",
      "H    0     0                    9590.0000000 9585.32670  0.05%     -    0s\n",
      "     0     0 9586.14083    0   18 9590.00000 9586.14083  0.04%     -    0s\n",
      "     0     0 9586.14083    0    6 9590.00000 9586.14083  0.04%     -    0s\n",
      "     0     0 9586.14083    0   11 9590.00000 9586.14083  0.04%     -    0s\n",
      "     0     0 9586.14083    0    6 9590.00000 9586.14083  0.04%     -    0s\n",
      "     0     0 9586.14083    0   13 9590.00000 9586.14083  0.04%     -    0s\n",
      "     0     0 9586.14083    0   11 9590.00000 9586.14083  0.04%     -    0s\n",
      "H    0     0                    9589.0000000 9586.14083  0.03%     -    0s\n",
      "     0     0 9589.00000    0    4 9589.00000 9589.00000  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  Lift-and-project: 1\n",
      "  Cover: 4\n",
      "  MIR: 5\n",
      "  StrongCG: 2\n",
      "  RLT: 1\n",
      "\n",
      "Explored 1 nodes (715 simplex iterations) in 0.36 seconds (0.03 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 6: 9589 9590 9591 ... 10770\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.589000000000e+03, best bound 9.589000000000e+03, gap 0.0000%\n",
      "\n",
      "User-callback calls 533, time in user-callback 0.23 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data\n",
    "\n",
    "#read the JSON file\n",
    "\n",
    "files = next(walk(path), (None, None, []))[2]\n",
    "\n",
    "for input_file in files:\n",
    "\n",
    "    file_path = path+input_file\n",
    "    print(\"inputfile\")\n",
    "    print(input_file)\n",
    "\n",
    "    input_content = read_input(file_path)\n",
    "\n",
    "    #TOLERANCE (values suggested by Garcia-Ayala's paper)\n",
    "    tolerance = (0.1, 0.05)\n",
    "\n",
    "    #DEPOTS\n",
    "    #list of depots\n",
    "    #format: [1, 2, 3]\n",
    "    depots = list()\n",
    "    for p in input_content['DEPOTS']:\n",
    "        depots.append(int(p))\n",
    "\n",
    "    #VERTICES\n",
    "    #list of vertices\n",
    "    #format: [1, 2, 3, 4]\n",
    "    vertices = list()\n",
    "    # for i in input_content['NODES'].keys():\n",
    "    #     vertices.append(int(i))\n",
    "\n",
    "    dictionary = dict()\n",
    "\n",
    "    # for a in input_content['NODES'].keys():\n",
    "    #     for b in input_content['NODES'][a].keys():\n",
    "    #         if (int(b),int(a)) not in dictionary.keys():\n",
    "    #             dictionary[int(a),int(b)] = int(input_content['NODES'][a][b]['DISTANCE']),int(input_content['NODES'][a][b]['DEMAND'])\n",
    "\n",
    "    for e in input_content['EDGES'].keys():\n",
    "        e_aux = e.split(',')\n",
    "        a = int(e_aux[0].split('(')[1])\n",
    "        b = int(e_aux[1].split(')')[0])\n",
    "        if (b,a) not in dictionary.keys():\n",
    "            dictionary[a,b] = int(input_content['EDGES'][e]['DISTANCE']),int(input_content['EDGES'][e]['DEMAND'])\n",
    "        if a not in vertices:\n",
    "            vertices.append(a)\n",
    "\n",
    "    #EDGES\n",
    "    #format: (2, 14)\n",
    "    #        (2, 3)\n",
    "    #DISTANCE\n",
    "    #format: {(2, 14): 34, (2, 3): 19}\n",
    "    #DEMAND\n",
    "    #format: {(2, 14): 240, (2, 3): 137}\n",
    "    edges, distance, demand = gp.multidict(dictionary)\n",
    "\n",
    "    #AVERAGE DEMAND\n",
    "    avg_demand = 0\n",
    "    for d in demand.keys():\n",
    "        avg_demand += demand[d]\n",
    "\n",
    "    avg_demand /= len(depots)\n",
    "\n",
    "    #EDGES DELTA\n",
    "    #dictionary of all the edges that have 'i' as one of its ends\n",
    "    #format: {2: [(2, 14), (2, 3), (2, 8)], 14: [(2, 14), (14, 7)]}\n",
    "    edges_delta = dict()\n",
    "\n",
    "    for i in vertices:\n",
    "        edges_delta[i] = list()\n",
    "        for e in edges:\n",
    "            if e[0] == i or e[1] == i:\n",
    "                edges_delta[i].append(e)\n",
    "\n",
    "    #DEPOT VERTEX\n",
    "    #tuples that relate a depot to a vertex\n",
    "    #format: [(1, 2), (1, 14)]\n",
    "    depot_vertex = list()\n",
    "\n",
    "    for p in depots:\n",
    "        for i in vertices:\n",
    "            depot_vertex.append((p, i))\n",
    "\n",
    "    matrix2 = import_floyd_warshall(file_path)\n",
    "\n",
    "    dictionary = dict()\n",
    "    for p in depots:\n",
    "        for e in edges:\n",
    "            dictionary[p,e] = min(matrix2[p][e[0]],matrix2[p][e[1]])\n",
    "\n",
    "\n",
    "    #DEPOT EDGE\n",
    "    #tuples that relate a depot to an edge\n",
    "    #format: ( 1 , (2, 14)  )\n",
    "    #        ( 1 , (2, 3)   )\n",
    "    #DEPOT DISTANCE\n",
    "    #dictionary with the distance between a depot and an edge\n",
    "    #format: {(1, (2, 14)): 60, (1, (2, 3)): 41}\n",
    "    depot_edge, depot_dist = gp.multidict(dictionary)\n",
    "\n",
    "    dictionary = dict()\n",
    "\n",
    "    #PARITY LOOSE\n",
    "    # list of vertices to assign if a vertex loose its parity or not\n",
    "    parity_loose = list()\n",
    "\n",
    "    #list of even parity vertices\n",
    "    vertices_even = list()\n",
    "    #list of odd parity vertices\n",
    "    vertices_odd = list()\n",
    "\n",
    "    for i in range(len(vertices)+1):\n",
    "        dictionary[i] = 0\n",
    "        if i != 0:\n",
    "            parity_loose.append(i)\n",
    "\n",
    "    for e in edges:\n",
    "        dictionary[e[0]] += 1\n",
    "        dictionary[e[1]] += 1\n",
    "\n",
    "    for i in range(len(vertices)+1):\n",
    "        if i != 0 and dictionary[i]%2 == 0:\n",
    "            vertices_even.append(i)\n",
    "        elif i != 0 and dictionary[i]%2 == 1:\n",
    "            vertices_odd.append(i)\n",
    "\n",
    "    dictionary = dict()\n",
    "\n",
    "    for i in vertices:\n",
    "        for p in depots:\n",
    "            dictionary[i,p] = 0\n",
    "\n",
    "    #PARITY\n",
    "    #dictionary that relates a vertex and a depot, and indicates its parity\n",
    "    parity = dictionary\n",
    "    #the same as the above but binary\n",
    "    parity_0 = dictionary\n",
    "\n",
    "    edges_sigma = dict()\n",
    "    edges_S = dict()\n",
    "    for e in edges:\n",
    "        edges_sigma[e] = list()\n",
    "        edges_S[e] = list()\n",
    "        for f in edges:\n",
    "            if (e[0] == f[0] or e[0] == f[1] or e[1] == f[0] or e[1] == f[1]) and (e != f):\n",
    "                edges_sigma[e].append(f)\n",
    "            elif (e != f):\n",
    "                edges_S[e].append(f)\n",
    "\n",
    "    edges_sigma_S = dict()\n",
    "    for e in edges:\n",
    "        edges_sigma_S[e] = list()\n",
    "        for i in edges_S[e]:\n",
    "            for j in edges_sigma[i]:\n",
    "                edges_sigma_S[e].append(j)\n",
    "\n",
    "    #declare model\n",
    "    model = gp.Model('RAP')\n",
    "\n",
    "    #decision variables\n",
    "    b = model.addVars(depot_dist, name=\"DepotEdgeDistance\")\n",
    "    x = model.addVars(depot_edge, vtype=gp.GRB.BINARY, name=\"DepotEdgeAssign\")\n",
    "    w = model.addVars(depot_vertex, vtype=gp.GRB.BINARY, name=\"DepotVertexIncident\")\n",
    "    z = model.addVars(parity, lb = 0, name = \"Parity\")\n",
    "    z_0 = model.addVars(parity_0, vtype=gp.GRB.BINARY, name = \"OddParity\")\n",
    "    r = model.addVars(parity_loose, vtype=gp.GRB.BINARY)\n",
    "\n",
    "    #constrains\n",
    "    constrain_2 = model.addConstrs((gp.quicksum(x[p,e] for p in depots) == 1 for e in edges), name='constrain2')\n",
    "    #constrain_3 = model.addConstrs((gp.quicksum(x[p,s] for s in edges_sigma_S[e]) - gp.quicksum(x[p,s] for s in edges_S[e]) >= x[p,e] - len(edges_S[e]) for p in depots for e in edges for S in edges), name='constrain 3')\n",
    "    constrain_4 = model.addConstrs((gp.quicksum(x[p,e]*demand[e] for e in edges) <= avg_demand*(1 + tolerance[0]) for p in depots), name='constrain4')\n",
    "    constrain_5 = model.addConstrs((gp.quicksum(x[p,e]*demand[e] for e in edges) >= avg_demand*(1 - tolerance[0]) for p in depots), name='constrain5')\n",
    "    constrain_6 = model.addConstrs((gp.quicksum(x[p,e] for e in edges_delta[i]) <= 9999*w[p,i] for p in depots for i in vertices), name='constrain6')\n",
    "    constrain_7 = model.addConstrs((gp.quicksum(x[p,e] for e in edges_delta[i]) >= w[p,i] for p in depots for i in vertices), name='constrain7')\n",
    "    constrain_8 = model.addConstrs((gp.quicksum(x[p,e] for e in edges_delta[i]) == 2*z[i,p]+z_0[i,p] for p in depots for i in vertices), name='constrain8')\n",
    "    constrain_9 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) >= r[i] for i in vertices_even), name='constrain9')\n",
    "    constrain_10 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) <= r[i]*len(depots) for i in vertices_even), name='constrain10')\n",
    "    constrain_11 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) - 1 >= r[i] for i in vertices_odd), name='constrain11')\n",
    "    constrain_12 = model.addConstrs((gp.quicksum(z_0[i,p] for p in depots) - 1 <= r[i]*len(depots) for i in vertices_odd), name='constrain12')\n",
    "    constrain_13 = model.addConstr((gp.quicksum(r[i] for i in vertices)/len(vertices) <= tolerance[1]), name='constrain13')\n",
    "\n",
    "    #objective\n",
    "    model.setObjective(x.prod(depot_dist), GRB.MINIMIZE)\n",
    "\n",
    "    #run\n",
    "    model.optimize(mycallback)\n",
    "\n",
    "    model.write(f\"{path}output/{input_file}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    i = 1\n",
    "    G = nx.Graph()\n",
    "    for p in depots:\n",
    "        edges_p = variable_regex_final(p)\n",
    "        \n",
    "        i +=1\n",
    "        for e in edges_p.keys():\n",
    "            if edges_p[e] > 0.9:\n",
    "                G.add_edge(e[0], e[1],color =50*i,weight = 2)\n",
    "    colors = nx.get_edge_attributes(G, 'color').values()\n",
    "    weights = nx.get_edge_attributes(G, 'weight').values()\n",
    "    pos = nx.planar_layout(G)\n",
    "    nx.draw(G, pos, edge_color=colors, width=list(weights), node_size=1, with_labels=True)\n",
    "    aux = input_file.split('.')[0]\n",
    "    plt.savefig(f'{path}IMG/{aux}.PNG')\n",
    "    plt.clf()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
